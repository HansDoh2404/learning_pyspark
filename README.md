# PySpark Tutorial for Beginners - Jupyter Notebooks

Welcome to the PySpark Tutorial for Beginners GitHub repository! This repository contains a collection of  notebooks used for learning pyspark from beginning. These notebooks provide hands-on examples and code snippets to help you understand and practice PySpark concepts covered in the tutorial video.

## Table of Contents

- [Introduction](#introduction)
- [Prerequisites](#prerequisites)
- [Getting Started](#getting-started)
- [Notebook Descriptions](#notebook-descriptions)
- [Usage](#usage)
- [Contact](#contact)

## Introduction

We covered various topics, including Spark installation, SparkContext, SparkSession, RDD transformations and actions, Spark DataFrames, Spark SQL, and more. These Jupyter notebooks are designed to complement the video content, allowing you to follow along, experiment, and practice your PySpark skills.

## Prerequisites

To make the notebooks run correctly, you should have the following prerequisites:

- Installing Python and Spark 

- Basic knowledge of Python programming.

- Understanding of data processing concepts (though no prior PySpark experience is required). 


## Getting Started

To get started with the Jupyter notebooks, follow these steps:

1. Clone this GitHub repository to your local machine using the following command:

   ```bash
   git clone https://github.com/HansDoh2404/learning_pyspark.git
   ```

2. Open the notebook you want to work on and start experimenting with PySpark.

## Notebook Descriptions

- **Notebook 1 - 01-PySpark-Get-Started**: Instructions and commands for setting the PySpark environment variables to use spark in jupyter notebook.

- **Notebook 2 - 02-Create-SparkContext**: Creating SparkContext objects in different PySpark versions.


- **Notebook 3 - 03-Create-SparkSession.ipynb**: Creating SparkSession objects in PySpark.

- **Notebook 4 - 04-RDD-Operations.ipynb**: Creating RDD and Demonstrating RDD transformations and actions.

- **Notebook 5 - 05-DataFrame-Intro.ipynb**: Introduction to Spark DataFrames and differences compared to RDD.

- **Notebook 6 - 06-DataFrame-from-various-data-source.ipynb**: Creating Spark Dataframe from various data sources.

- **Notebook 7 - 07-DataFrame-Operations.ipynb**: Performing Spark Dataframe operations like filtering, aggregation, etc.

- **Notebook 8 - 08-Spark-SQL.ipynb**: Converting Spark Dataframe to a temporary table or view and performing SQL operations using Spark SQL.

Feel free to explore and run these notebooks at your own pace.

## Usage

These notebooks are meant for self-learning and practice to gain a deeper understanding of PySpark syntax and operations. Experiment with the code, modify it and try additional exercises to solidify your skills.

## Contact

Contributor : [@Hans Ariel](https://www.linkedin.com/in/hans-ariel-doh-59a31a2ba/) - hansearieldo@gmail.com
<br />
Project link : https://github.com/HansDoh2404/learning_pyspark.git 