{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49b0622d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SPARK_HOME'] = \"/opt/spark\"\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = \"jupyter\"\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS'] = \"lab\"\n",
    "os.environ['PYSPARK_PYTHON'] = \"python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa6fd44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"DataFrame-Operations\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe78f75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "head -n 10 data/stocks.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38596e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the synthetic data into a DataFrame\n",
    "data_file_path = \"./data/stocks.txt\"\n",
    "df = spark.read.csv(data_file_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbc7ece",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display schema of DataFrame\n",
    "df.printSchema()\n",
    "\n",
    "# Show the initial DataFrame\n",
    "print(\"Initial DataFrame:\")\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2f5c299",
   "metadata": {},
   "source": [
    "# **Select: Choose specific columns**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f32ab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select specific columns\n",
    "selected_columns = df.select(\"id\", \"name\", \"price\")\n",
    "print(\"Selected Columns:\")\n",
    "selected_columns.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1507c0bc",
   "metadata": {},
   "source": [
    "# **Filter: Apply conditions to filter rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fcd4d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter rows based on a condition\n",
    "filtered_data = df.filter(df.quantity > 20)\n",
    "print(\"Filtered Data:\", filtered_data.count())\n",
    "filtered_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "737b1a55",
   "metadata": {},
   "source": [
    "### GroupBy: Group data based on specific columns \n",
    "### Aggregations: Perform functions like sum, average, etc., on grouped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cda821",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GroupBy and Aggregations\n",
    "grouped_data = df.groupBy(\"category\").agg({\"quantity\": \"sum\", \"price\": \"avg\"})\n",
    "print(\"Grouped and Aggregated Data:\")\n",
    "grouped_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb31f9b",
   "metadata": {},
   "source": [
    "### Join: Combine multiple DataFrames based on specified columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "618a3d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join with another DataFrame\n",
    "df2 = df.select(\"id\", \"category\").limit(10)\n",
    "joined_data = df.join(df2, \"id\", \"inner\")\n",
    "print(\"Joined Data:\")\n",
    "joined_data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd62d89",
   "metadata": {},
   "source": [
    "### Sort: Arrange rows based on one or more columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e503df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by a column\n",
    "sorted_data = df.orderBy(\"price\")\n",
    "print(\"Sorted Data:\")\n",
    "sorted_data.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cc4f123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by a column desc\n",
    "from pyspark.sql.functions import col, desc\n",
    "sorted_data = df.orderBy(col(\"price\").desc(), col(\"id\").desc())\n",
    "print(\"Sorted Data Descending:\")\n",
    "sorted_data.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86576cb7",
   "metadata": {},
   "source": [
    "### Distinct: Get unique rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5686c05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get distinct product category\n",
    "distinct_rows = df.select(\"category\").distinct()\n",
    "print(\"Distinct Product Categories:\")\n",
    "distinct_rows.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebb15e7",
   "metadata": {},
   "source": [
    "### Drop: Remove specified columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83cef29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns\n",
    "dropped_columns = df.drop(\"quantity\", \"category\")\n",
    "print(\"Dropped Columns:\")\n",
    "dropped_columns.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97861df9",
   "metadata": {},
   "source": [
    "### WithColumn: Add new calculated columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e674e308",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new calculated column\n",
    "df_with_new_column = df.withColumn(\"revenue\", df.quantity * df.price)\n",
    "print(\"DataFrame with New Column:\")\n",
    "df_with_new_column.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c23d4b4",
   "metadata": {},
   "source": [
    "### Alias: Rename columns for better readability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef3a553",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns using alias\n",
    "df_with_alias = df.withColumnRenamed(\"price\", \"product_price\")\n",
    "print(\"DataFrame with Aliased Column:\")\n",
    "df_with_alias.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2fab6b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop the SparkSession\n",
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de81cb85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
