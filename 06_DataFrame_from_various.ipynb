{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97efa9b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['SPARK_HOME'] = \"/opt/spark\"\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = \"jupyter\"\n",
    "os.environ['PYSPARK_DRIVER_PYTHON_OPTS'] = \"lab\"\n",
    "os.environ['PYSPARK_PYTHON'] = \"python\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bf52cce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Create a SparkSession\n",
    "spark = SparkSession.builder.appName(\"Create-DateFrame\").getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed8e5d8a",
   "metadata": {},
   "source": [
    "# **Read CSV file into DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc54312",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash \n",
    "head -10 ./data/products.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2074c40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file into DataFrame\n",
    "csv_file_path = \"./data/products.csv\"\n",
    "df = spark.read.csv(csv_file_path, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143ec7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display schema of DataFrame\n",
    "df.printSchema()\n",
    "\n",
    "# Display content of DataFrame\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2924894",
   "metadata": {},
   "source": [
    "# **Read CSV with an explicit schema definition**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1918dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary types\n",
    "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DoubleType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e7ed64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the schema\n",
    "schema = StructType([\n",
    "    StructField(name=\"id\", dataType=IntegerType(), nullable=True),\n",
    "    StructField(name=\"name\", dataType=StringType(), nullable=True),\n",
    "    StructField(name=\"category\", dataType=StringType(), nullable=True),\n",
    "    StructField(name=\"quantity\", dataType=IntegerType(), nullable=True),\n",
    "    StructField(name=\"price\", dataType=DoubleType(), nullable=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "434e5bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file into DataFrame with schema definition\n",
    "csv_file_path = \"./data/products.csv\"\n",
    "df = spark.read.csv(csv_file_path, header=True, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e7984e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display schema of DataFrame\n",
    "df.printSchema()\n",
    "\n",
    "# Display content of DataFrame\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3575535",
   "metadata": {},
   "source": [
    "# **Read CSV with inferSchema**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b1f19119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read CSV file into DataFrame with inferSchema\n",
    "csv_file_path = \"./data/products.csv\"\n",
    "df = spark.read.csv(csv_file_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1000e55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display schema of DataFrame\n",
    "df.printSchema()\n",
    "\n",
    "# Display content of DataFrame\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b234efd",
   "metadata": {},
   "source": [
    "# **Read JSON file into DataFrame**\n",
    "\n",
    "## Single Line JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebf86d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "head -10 data/products_singleline.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a79e21bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read single line JSON\n",
    "# Each row is a JSON record, records are separated by new line\n",
    "json_file_path = \"./data/products_singleline.json\"\n",
    "df = spark.read.json(json_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bde191",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display schema of DataFrame\n",
    "df.printSchema()\n",
    "\n",
    "# Display content of DataFrame\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "932c0258",
   "metadata": {},
   "source": [
    "## Multi-lines JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dab7348",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "head -20 data/products_multiline.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "185b54e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read multi-line JSON\n",
    "# JSON is an array of record, records are separated by a comma.\n",
    "# each record is defined in multiple lines\n",
    "json_file_path = \"./data/products_multiline.json\"\n",
    "df = spark.read.json(json_file_path, multiLine=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a39d075",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display schema of DataFrame\n",
    "df.printSchema()\n",
    "\n",
    "# Display content of DataFrame\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01cb9bae",
   "metadata": {},
   "source": [
    "# **Writing into parquet file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90ecdb47",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# write dataframe into parquet file\n",
    "parquet_file_path = \"./data/products.parquet\"\n",
    "df.write.mode(\"overwrite\").parquet(parquet_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe74c48",
   "metadata": {},
   "source": [
    "# **Read parquet file into DataFrame**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d400a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet(parquet_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccffbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display schema of DataFrame\n",
    "df.printSchema()\n",
    "\n",
    "# Display content of DataFrame\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a10007ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f15a295",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
